# edubert

Readme to be updated with instructions very soon.

Models trained using [Transformers by Huggingface](https://github.com/huggingface/transformers) and compatible with it (PyTorch implementation).

EduBERT (.tar.gz, ±388.7MB): https://storage.googleapis.com/edubert/edubert.tar.gz

DistilEduBERT (.tar.gz, ±235.5MB): https://storage.googleapis.com/edubert/distiledubert.tar.gz


## Citing

Tentative:
```
@inproceedings{clavié_gal_2020,
title={EduBERT: Pretrained Deep Language Models for Learning Analytics},
booktitle={To Be Published in the Companion Proceedings of the Tenth International Conference on Learning Analytics And Knowledge - LAK 20},
author={Clavié, Benjamin and Gal, Kobi},
year={2020}}
```
